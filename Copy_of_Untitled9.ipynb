{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eman-diab-hussein/deep/blob/main/Copy_of_Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14gmECwGeWuI",
        "outputId": "61f9948a-0796-4f7a-f40d-5cc759199017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "IPF-8qBM0AB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your datasets are in the root of your Google Drive\n",
        "train_path = '/content/drive/MyDrive/vegat'\n",
        "test_path = '/content/drive/MyDrive/testing'\n",
        "import os\n",
        "\n",
        "print(\"training\")\n",
        "print(os.listdir(train_path))\n",
        "\n",
        "print(\"testing\")\n",
        "print(os.listdir(test_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3YxyGq7mS5w",
        "outputId": "4941b3dc-4997-4659-ff02-6465e9a936ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training\n",
            "['elephant', 'cuc', 'machroom']\n",
            "testing\n",
            "['mashrom', 'cuc1', 'elephant1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Define the training and validation base directories\n",
        "train_dir = '/content/drive/MyDrive/vegat'\n",
        "validation_dir = '/content/drive/MyDrive/testing'\n",
        "\n",
        "# Directory with training class_1 pictures\n",
        "train_eggplant_dir = os.path.join(train_dir, 'elephant')\n",
        "# Directory with training class_2 pictures\n",
        "train_cucumber_dir = os.path.join(train_dir, 'cuc')\n",
        "# Directory with training class_3 pictures\n",
        "train_mushroom_dir = os.path.join(train_dir, 'machroom')\n",
        "\n",
        "# Directory with validation class_1 pictures\n",
        "validation_eggplant_dir = os.path.join(validation_dir, 'mashrom')\n",
        "# Directory with validation class_2 pictures\n",
        "validation_cucumber_dir = os.path.join(validation_dir, 'cuc1')\n",
        "# Directory with validation class_3 pictures\n",
        "validation_mushroom_dir = os.path.join(validation_dir, 'elephant1')\n",
        "\n",
        "# Check the number of images for each class and set\n",
        "print(f\"There are {len(os.listdir(train_eggplant_dir))} images of eggplant for training.\\n\")\n",
        "print(f\"There are {len(os.listdir(train_cucumber_dir))} images of cuc for training.\\n\")\n",
        "print(f\"There are {len(os.listdir(train_mushroom_dir))} images of machoom for training.\\n\")\n",
        "print(f\"There are {len(os.listdir(validation_eggplant_dir))} images of eggplant for validation.\\n\")\n",
        "print(f\"There are {len(os.listdir(validation_cucumber_dir ))} images of cuc1  for validation.\\n\")\n",
        "print(f\"There are {len(os.listdir(validation_mushroom_dir))} images of mushroom for validation.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBY39bWG1jcs",
        "outputId": "1120b65a-cf36-43d9-e37e-e68b8ffd5b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 70 images of eggplant for training.\n",
            "\n",
            "There are 60 images of cuc for training.\n",
            "\n",
            "There are 72 images of machoom for training.\n",
            "\n",
            "There are 50 images of eggplant for validation.\n",
            "\n",
            "There are 57 images of cuc1  for validation.\n",
            "\n",
            "There are 54 images of mushroom for validation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "print(\"Sample eggplant image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(train_eggplant_dir, os.listdir(train_eggplant_dir)[0])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample cucumber image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(train_cucumber_dir, os.listdir(train_cucumber_dir)[0])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample machroom image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(train_mushroom_dir, os.listdir(train_mushroom_dir)[0])}\"))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rPmWilBb3hFd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "bde6e72e-5935-4558-a06b-52ca0af1b845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample eggplant image:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-dbd6bb150901>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample eggplant image:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{os.path.join(train_eggplant_dir, os.listdir(train_eggplant_dir)[0])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/vegat/elephant'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sRe2jQ8ZgCHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the first example of a horse\n",
        "sample_image  = load_img(f\"{os.path.join(train_eggplant_dir, os.listdir(train_eggplant_dir)[0])}\")\n",
        "\n",
        "# Convert the image into its numpy array representation\n",
        "sample_array = img_to_array(sample_image)\n",
        "\n",
        "print(f\"Each image has shape: {sample_array.shape}\")"
      ],
      "metadata": {
        "id": "d9tTl72e98nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-hub\n"
      ],
      "metadata": {
        "id": "DWYiH9YJncUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = '/content/drive/MyDrive/vegat'\n",
        "VALIDATION_DIR = '/content/drive/MyDrive/testing'\n",
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  ### START CODE HERE\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "  train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=64,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen =  ImageDataGenerator(rescale=1.0/255,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=64,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "5lTpKjn0qiZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(train_dir, validation_dir)"
      ],
      "metadata": {
        "id": "8sV-Pvsg-vCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "weazZZptBVGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths to your training and testing datasets\n",
        "train_data_dir = '/content/drive/MyDrive/vegat'\n",
        "test_data_dir = '/content/drive/MyDrive/testing'\n",
        "\n",
        "# Define image size and batch size\n",
        "image_size = (224, 224)  # Adjust the size as needed for MobileNetV2\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Image normalization for testing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches using train_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Assumes you have three classes\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Flow validation images in batches using test_datagen\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Assumes you have three classes\n",
        "    shuffle=False  # Do not shuffle for better evaluation\n",
        ")\n",
        "\n",
        "# Download MobileNetV2 model without the top classification layers\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build a new model on top of the pre-trained base\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Three classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "HPDD-S4zwg3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the mobileNetV2 weights\n",
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\\\n",
        "    -O /tmp/mobilenet_v2_weights.h5"
      ],
      "metadata": {
        "id": "ClmXenmVDH2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/mobilenet_v2_weights.h5'"
      ],
      "metadata": {
        "id": "pn_-IBO1A2Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pre_trained_model(local_weights_file, include_top=False):\n",
        "  ### START CODE HERE\n",
        "  pre_trained_model = MobileNetV2(input_shape = (150, 150, 3),\n",
        "                                  include_top = False,\n",
        "                                  weights = None)\n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "  # Make all the layers in the pre-trained model non-trainable\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return pre_trained_model\n"
      ],
      "metadata": {
        "id": "o-Z60TdrEpmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = create_pre_trained_model(local_weights_file)\n",
        "\n",
        "# Print the model\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "id": "QsYo8moCALNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "Mi93ZMhqu5LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "UmnKrnBq4MKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: output_of_last_layer\n",
        "def output_of_last_layer(pre_trained_model):\n",
        "  ### START CODE HERE\n",
        "  last_desired_layer = pre_trained_model.get_layer('mixed7')\n",
        "  print('last layer output shape: ', last_desired_layer.output_shape)\n",
        "  last_output = last_desired_layer.output\n",
        "  print('last layer output: ', last_output)\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return last_output"
      ],
      "metadata": {
        "id": "NoqNw7tgHa7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The pretrained model has type: {type(pre_trained_model)}\")"
      ],
      "metadata": {
        "id": "Kpm_CYvYHi1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib\n"
      ],
      "metadata": {
        "id": "b17vvgcf2j9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFVQl4akKMVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load pre-trained MobileNetV2 model\n",
        "pre_trained_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the layers up to a certain index (e.g., all layers up to block 10)\n",
        "freeze_up_to_layer = 10\n",
        "\n",
        "for layer in pre_trained_model.layers[:freeze_up_to_layer]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "4wFU7naPQSMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53rHPVdAVjwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect parameters\n",
        "total_params = model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ],
      "metadata": {
        "id": "Erm1YzZHw4Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Assuming you have a `test_generator` for your test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "wn2hWcLpRmvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have 'history' variable containing training history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Plotting training and validation accuracies\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Plotting training and validation losses\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rI88G-1X2sXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "4ea8f93c-bada-423e-ce5e-b4037974c762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e89f35dfc18d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming you have 'history' variable containing training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    }
  ]
}